{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms.fake import FakeListLLM\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.llms import Replicate\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import JinaChat\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "import vertexai as vx\n",
    "\n",
    "from config import set_environment\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "set_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"python_repl\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = [\"Action: Python_REPL\\nAction Input: print(2 + 2)\", \"Final Answer: 4\"]\n",
    "\n",
    "llm = FakeListLLM(responses=responses)\n",
    "\n",
    "agent = initialize_agent(tools=tools, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: Python_REPL\n",
      "Action Input: print(2 + 2)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m4\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: 4\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"whats 2+2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0., model=\"gpt-3.5-turbo-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should add 1726 and 15\n",
      "Action: [Python_REPL]\n",
      "Action Input: 1726 + 15\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the Python_REPL tool\n",
      "Action: [Python_REPL]\n",
      "Action Input: print(1726 + 15)\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the Python_REPL tool\n",
      "Action: [Python_REPL]\n",
      "Action Input: print(1726 + 15)\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the Python_REPL tool\n",
      "Action: [Python_REPL]\n",
      "Action Input: print(1726 + 15)\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the Python_REPL tool\n",
      "Action: [Python_REPL]\n",
      "Action Input: print(1726 + 15)\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the Python_REPL tool\n",
      "Action: [Python_REPL]\n",
      "Action Input: print(1726 + 15)\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the Python_REPL tool\n",
      "Action: [Python_REPL]\n",
      "Action Input: print(1726 + 15)\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the Python_REPL tool\n",
      "Action: [Python_REPL]\n",
      "Action Input: print(1726 + 15)\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the Python_REPL tool\n",
      "Action: [Python_REPL]\n",
      "Action Input: print(1726 + 15)\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the Python_REPL tool\n",
      "Action: [Python_REPL]\n",
      "Action Input: print(1726 + 15)\u001b[0m\n",
      "Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 1741\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1741'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "agent.run(\"whats 1726 + 15\")\n",
    "\n",
    "# Observation: [Python_REPL] is not a valid tool, try one of [Python_REPL]. WHY???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "japan\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceHub(\n",
    "    model_kwargs={'temperature':0.5,'max_length':64},\n",
    "    repo_id=\"google/flan-t5-xxl\"\n",
    ")\n",
    "\n",
    "prompt = \"In which country is Tokyo?\"\n",
    "completion = llm(prompt)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Cloud Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Who was the US president during the Twin Tower attack??\n",
      "Answer: Let's think step by step.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The Twin Towers were attacked on September 11, 2001. The president of the United States at that time was George W. Bush.\\n\\nThe final answer is George W. Bush'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "vx.init(project='my-project-test-387510')\n",
    "\n",
    "llm = VertexAI()\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)\n",
    "question = \"Who was the US president during the Twin Tower attack??\"\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def fizzBuzz(n):\n",
      "    answer = []\n",
      "    for i in range(1, n + 1):\n",
      "        if i % 3 == 0 and i % 5 == 0:\n",
      "            answer.append(\"FizzBuzz\")\n",
      "        elif i % 3 == 0:\n",
      "            answer.append(\"Fizz\")\n",
      "        elif i % 5 == 0:\n",
      "            answer.append(\"Buzz\")\n",
      "        else:\n",
      "            answer.append(str(i))\n",
      "    return answer\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "Using py, given an integer n, return a string array answer (1-indexed) where:\n",
    "answer[i] == \"FizzBuzz\" if i is divisible by 3 and 5.\n",
    "answer[i] == \"Fizz\" if i is divisible by 3.\n",
    "answer[i] == \"Buzz\" if i is divisible by 5.\n",
    "answer[i] == i (as a string) if none of the above conditions are true.\n",
    "\"\"\"\n",
    "llm = VertexAI(model_name=\"code-bison\")\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JinaAi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ich liebe generative KI!', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = JinaChat(temperature=0.)\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"Translate this sentence from English to German: I love generative AI!\"\n",
    "    )\n",
    "]\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You can try adding some vegetables to your pasta with cheese, or you can have a salad on the side. Another option is to replace the pasta with zucchini noodles, which are a healthier alternative.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You help a user find a nutritious and tasty food to eat in one word.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=\"I like pasta with cheese, but I need to eat more vegetables, what should I eat?\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
